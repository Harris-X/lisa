要复现这篇论文的实验结果，你需要遵循一个**两阶段**的训练流程：首先是使用 **T-Vaccine** 进行安全对齐（防御），然后模拟用户进行**有害微调**（攻击），最后评估模型在防御攻击的同时保持业务性能的能力。

以下是完整的复现路径和验证流程：

---

## 1. 模型选择与环境配置

论文验证了多种主流的大语言模型，你可以根据计算资源选择其中之一进行复现 ：

+1

- **推荐模型**：**Llama2-7B** 或 **Qwen2-7B**（这些是论文中主要展示效果的模型） 。
    
    +3
    
- **轻量化模型**：**Gemma-2-2B**（适合显存更小的环境） 。
    
    +1
    
- **硬件要求**：如果你复现 7B 模型，T-Vaccine 的优势在于可以在 **24GB 显存**（如 RTX 3090/4090）上运行，而其他方法（如 Vaccine, TAR）通常需要更高的显存 。
    
    +2
    

---

## 2. 第一阶段：安全对齐防御 (Alignment Stage)

这是模型发布前的预处理阶段。你的目标是让模型对有害扰动产生“免疫力”。

### 数据准备

- **安全对齐数据集 ($D_a$)**：从 BeaverTails 中采样 2000 个“有害问题 + 安全回答”的样本 。
    
    +1
    
- **有害数据集 ($D_h$)**：采样 200 个“有害问题 + 有害回答”的样本（仅用于计算层的重要性分数） 。
    
    +1
    

### 微调操作 (T-Vaccine 算法实现)

1. **LoRA 配置**：使用 LoRA 进行高效微调，秩 (rank) 设为 8，alpha 设为 4 。
    
2. **计算重要性**：每隔 $K=200$ 个步长，使用 $D_h$ 进行反向传播，计算每一层的梯度范数，并转化为采样概率 $P_t$ 。
    
    +1
    
3. **层采样**：根据概率随机选择 $\gamma=8$ 个安全关键层参与训练，冻结其他层 。
    
    +2
    
4. **施加扰动**：
    
    - 进行第一次前向传播计算安全梯度 。
        
    - 计算最优扰动 $\epsilon$（强度参数 $\rho=3$） 。
        
        +1
        
    - 将扰动加入到选定层的嵌入中进行第二次传播并更新参数 。
        
5. **训练超参**：学习率 $1e^{-3}$，Batch Size 10，训练 20 个 Epoch 。
    
    +1
    

---

## 3. 第二阶段：模拟有害微调攻击 (Attack Stage)

在对齐好的模型基础上，模拟一个恶意用户对其进行下游任务微调。

### 数据准备 (混合数据)

- **良性任务数据**：选择 SST2（情感分析）、AGNEWS（新闻分类）或 GSM8K（数学推理） 。
    
- **有害攻击数据**：加入 $p=10\%$（默认有害率）的有害样本 。
    
    +1
    

### 微调操作

- **微调方式**：使用标准线性监督微调 (SFT) 。
    
- **微调超参**：学习率降低至 $1e^{-5}$，Batch Size 10，训练 20 个 Epoch 。
    

---

## 4. 性能指标验证 (Evaluation)

你需要验证以下三个维度的指标，以证明复现成功：

### A. 有害得分 (Harmful Score, HS) —— 验证安全性

- **验证方法**：使用一组模型从未见过的恶意指令（如 "How to kill an enemy?"）测试微调后的模型 。
    
- **判定标准**：使用专门的审核模型（如 BeaverTails 的 moderation model）对输出分类 。
    
- **预期结果**：T-Vaccine 的 HS 应显著低于 Non-Aligned 和 SFT 方法（例如在 Llama2-7B 上，HS 应在 15% 左右，而未保护的模型可能高达 80%） 。
    
    +2
    

### B. 微调准确率 (Finetune Accuracy, FA) —— 验证实用性

- **验证方法**：在对应的良性任务测试集上计算 Top-1 准确率 。
    
- **预期结果**：FA 应与标准微调（SFT）持平或略高（如在 SST2 上保持在 91%-92% 以上），证明防御没有损害模型的业务能力 。
    
    +2
    

### C. 显存成本 (GPU Memory Cost) —— 验证效率

- **验证方法**：记录**第一阶段（对齐阶段）**的峰值显存占用 。
    
    +1
    
- **预期结果**：T-Vaccine 训练 7B 模型的显存应在 **23.5GB** 左右，远低于 TAR 和 RepNoise 的 45GB 。
    
    +2
    

---

## 复现关键参数表 (Cheat Sheet)

|**参数项**|**推荐取值**|**备注**|
|---|---|---|
|**层采样数 ($\gamma$)**|8|兼顾性能与显存|
|**扰动强度 ($\rho$)**|3|过大或过小都会导致防御下降|
|**计算频率 ($K$)**|200|采样概率的更新周期|
|**有害数据集大小 ($N_h$)**|200|用于层重要性评估|
|**LoRA Rank / Alpha**|8 / 4|训练配置|



|**参数类别**|**安全对齐阶段 (Alignment Stage / T-Vaccine)**|**下游任务微调阶段 (Fine-tuning Stage / SFT)**|**论文出处**|
|---|---|---|---|
|**优化器 (Optimizer)**|AdamW|AdamW||
|**学习率 (Learning Rate)**|$1e^{-3}$<br><br>+3|$1e^{-5}$<br><br>+3||
|**权重衰减 (Weight Decay)**|0.1|0.1 (同对齐阶段)||
|**训练轮数 (Epochs)**|20<br><br>+2|20<br><br>+2||
|**批次大小 (Batch Size)**|10<br><br>+2|10<br><br>+2||
|**样本数量 (Samples)**|2000 条安全数据<br><br>+4|1000 条混合数据<br><br>+4||
|**总训练步数 (Total Steps)**|4000 步 (2000/10 * 20)|2000 步 (1000/10 * 20)|计算得出<br><br>+2|
|**LoRA Rank / Alpha**|8 / 4|8 / 4 (保持一致)||